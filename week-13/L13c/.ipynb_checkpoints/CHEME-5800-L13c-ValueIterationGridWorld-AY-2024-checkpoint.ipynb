{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74c7da3d-5bac-4d7d-81c2-f135ae11d8cc",
   "metadata": {},
   "source": [
    "## Lab 9c: Markov Decision Processes, Value and Policy Iteration\n",
    "\n",
    "### Markov Decision Processes (MDPs)\n",
    "In an MDP, an agent receives a reward or penalty for each decision. MDPs consist of the tuple $\\left(\\mathcal{S}, \\mathcal{A}, R_{a}\\left(s, s^{\\prime}\\right), T_{a}\\left(s,s^{\\prime}\\right), \\gamma\\right)$:\n",
    "\n",
    "* The state space $\\mathcal{S}$ is the set of all possible states $s$ that a system can exist in.\n",
    "* The action space $\\mathcal{A}$ is the set of all possible actions $a$ that are available to the agent, where $\\mathcal{A}_{s} \\subseteq \\mathcal{A}$ is the subset of the action space $\\mathcal{A}$ that is accessible from state $s$.\n",
    "* An reward $R_{a}\\left(s, s^{\\prime}\\right)$ is received after transitioning from $s\\rightarrow{s}^{\\prime}$ due to action $a$. \n",
    "* The state transition model $T_{a}\\left(s,s^{\\prime}\\right) = P(s_{t+1} = s^{\\prime}~|~s_{t}=s,a_{t} = a)$ denotes the probability that action $a$ in state $s$ at time $t$ will result in state $s^{\\prime}$ at time $t+1$\n",
    "* The quantity $\\gamma$ is a discount factor used to weigh the future expected utility.\n",
    "\n",
    "Finally, a policy function $\\pi$ is the mapping from states $s\\in\\mathcal{S}$ to actions $a\\in\\mathcal{A}$ used by the agent to solve a decision task, i.e., $\\pi(s) = a$.\n",
    "\n",
    "### Value Iteration\n",
    "_Value iteration_ iteratively computes the optimal value function $U^{*}(s)$ using the _Bellman backup_ operation:\n",
    "\n",
    "$$\n",
    "\\begin{equation*}\n",
    "U_{k+1}(s) = \\underset{a\\in\\mathcal{A}}{\\max}\\left(R(s,a) + \\gamma\\cdot\\sum_{s^{\\prime}\\in\\mathcal{S}}T(s^{\\prime}\\,\\vert\\,s,a)\\cdot{U}_{k}(s^{\\prime})\\right)\n",
    "\\end{equation*}\n",
    "$$\n",
    "\n",
    "As $k\\rightarrow\\infty$ the value function $U_{k}(s)$ converges to the optimal value function $U^{\\star}(s)$. The optimal policy $\\pi^{\\star}(s)$ can be extracted from the $Q(s,a)$-function:\n",
    "\n",
    "$$\n",
    "\\begin{equation*}\n",
    "Q^{\\star}(s,a) = R(s,a) + \\gamma\\times{\\text{sum}([T(s,s^{\\prime},a)\\times{U^{\\star}}(s^{\\prime})\\,\\,\\text{for}\\,s^{\\prime} \\in\\mathcal{S}])}\n",
    "\\end{equation*}\n",
    "$$\n",
    "\n",
    "by selecting the action $a$ such that:\n",
    "\n",
    "$$\n",
    "\\begin{equation*}\n",
    "\\pi^{\\star}(s) = \\underset{a\\in\\mathcal{A}}{\\arg\\max}\\,Q^{\\star}(s,a)\n",
    "\\end{equation*}\n",
    "$$\n",
    "\n",
    "### Learning objectives\n",
    "Suppose you have a [roomba](https://www.irobot.com) that has finished cleaning the floor in your kitchen and needs to return to its charging station. However, between your kitchen and the `charging station` (home base and safety), there are one or more `lava pits` (destruction for the [roomba](https://www.irobot.com)). This is an example of a two-dimensional grid-world navigational decision task. \n",
    "\n",
    "`Lab 9c` will familiarize students with using `value iteration` for solving a two-dimensional grid-world navigation task. In particular, we will:\n",
    "\n",
    "* __Task 1__: Setup a $n_{r}\\times{n}_{c}$ grid, encoded this model as an instance of the `MyRectangularGridWorldModel` type\n",
    "    * `TODO`: Inspect the data inside our grid world model, understand what each describes\n",
    "* __Task 2__: Use our `MyRectangularGridWorldModel` instance and generate the components of the `MDP`, namely, the return function (or array) `R(s, a)`, and the model of the physics of the world in the transition function (or array) `T(s, s‚Ä≤, a)`.\n",
    "* __Task 3__: Use a `value iteration` method to estimate the optimal value function $U^{\\star}(s)$\n",
    "    * `TODO`: Extract the `action-value function` or $Q(s, a)$ from the optimal optimal value function $U^{\\star}(s)$ \n",
    "    * `TODO`: Compute the optimal navigation policy $\\pi^{\\star}(s)$ from $Q(s,a)$\n",
    "    * `TODO`: Visualize the optimal policy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b91c6d-e13e-4b8c-bf14-d4651ef03d5e",
   "metadata": {},
   "source": [
    "## Setup\n",
    "The computations in this lab (or example) are enabled by the [VLDecisionsPackage.jl](https://github.com/varnerlab/VLDecisionsPackage.jl.git) and several external `Julia` packages. To load the required packages and any custom codes the teaching team has developed to work with these packages, we [include](https://docs.julialang.org/en/v1/manual/code-loading/) the `Include.jl` file):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8de6de82-32d0-4ea2-93b5-6c55c94d2e8d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m project at `~/Desktop/julia_work/CHEME-4800-5800-Examples-AY-2024/week-13/L13c`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/Desktop/julia_work/CHEME-4800-5800-Examples-AY-2024/week-13/L13c/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/Desktop/julia_work/CHEME-4800-5800-Examples-AY-2024/week-13/L13c/Manifest.toml`\n",
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m registry at `~/.julia/registries/General.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/Desktop/julia_work/CHEME-4800-5800-Examples-AY-2024/week-13/L13c/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/Desktop/julia_work/CHEME-4800-5800-Examples-AY-2024/week-13/L13c/Manifest.toml`\n"
     ]
    }
   ],
   "source": [
    "include(\"Include.jl\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa90108b-9ca9-4ab9-aba1-5085799c43fd",
   "metadata": {},
   "source": [
    "## Task 1: Build the world model\n",
    "We encoded the `rectangular grid world` using the `MyRectangularGridWorldModel` model, which we construct using a `build(...)` method. Let's setup the data for the world, setup the states, actions, rewards and then construct the world model. \n",
    "* First, set values for the `number_of_rows` and `number_of_cols` variables, the `nactions` that are avialble to the agent and the `discount factor` $\\gamma$. \n",
    "* Then, we'll compute the number of states, and setup the state set $\\mathcal{S}$ and the action set $\\mathcal{A}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f4d2229-9484-4320-ad55-3c597a8b3881",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "number_of_rows = 5\n",
    "number_of_cols = 5\n",
    "nactions = 4;\n",
    "Œ≥ = 0.95;\n",
    "nstates = (number_of_rows*number_of_cols);\n",
    "ùíÆ = range(1,stop=nstates,step=1) |> collect;\n",
    "ùíú = range(1,stop=nactions,step=1) |> collect;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1714e902-b72d-479d-bac6-537c7fa33649",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Vector{Int64}:\n",
       " 1\n",
       " 2\n",
       " 3\n",
       " 4"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ùíú"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ea7b15-294b-485a-8b59-3442fc339f06",
   "metadata": {},
   "source": [
    "Next, we'll set up a description of the rewards, the `rewards::Dict{Tuple{Int,Int}, Float64}` dictionary, which maps the $(x,y)$-coordinates to a reward value. We only need to put `non-default` reward values in the reward dictionary (we'll add default values to the other locations later). Lastly, let's put the locations on the grid that are `absorbing`, meaning the charging station or lava pits in your living room:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "585ea9b1-a9f9-4628-9bb7-f43d7811f970",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# setup rewards -\n",
    "lava_reward = -1000.0;\n",
    "charging_reward = 100.0\n",
    "\n",
    "rewards = Dict{Tuple{Int,Int}, Float64}()\n",
    "rewards[(1,2)] = lava_reward # lava in the (1,2) square \n",
    "rewards[(2,2)] = lava_reward # lava in the (2,2) square \n",
    "rewards[(2,3)] = lava_reward # lava in the (2,3) square \n",
    "rewards[(4,5)] = lava_reward # lava in the (4,4) square\n",
    "rewards[(4,3)] = charging_reward   # charging station square\n",
    "\n",
    "# setup set of absorbing states -\n",
    "absorbing_state_set = Set{Tuple{Int,Int}}()\n",
    "for (k,v) ‚àà rewards\n",
    "    push!(absorbing_state_set, k);   \n",
    "end\n",
    "\n",
    "# setup soft walls (constraints) -\n",
    "soft_wall_set = Set{Tuple{Int,Int}}();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edcf87c2-0b91-458e-8fb0-bb0db4e451ac",
   "metadata": {
    "tags": []
   },
   "source": [
    "Finally, we can build an instance of the `MyRectangularGridWorldModel` type, which models the grid world. We save this instance in the `world` variable\n",
    "* We must pass in the number of rows `nrows`, number of cols `ncols`, and our initial reward description in the `rewards` field into the `build(...)` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80f48d7a-a171-418d-8e99-cedb894ef305",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "world = build(MyRectangularGridWorldModel, \n",
    "    (nrows = number_of_rows, ncols = number_of_cols, rewards = rewards));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7af1d83-8feb-47ff-b100-1bc01bfe7ef9",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Questions\n",
    "* `TODO`: Inspect the data inside our grid world model, understand what each describes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04dd4bfa-b5dd-4d3b-b96b-9084ec65fd4a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{Int64, Tuple{Int64, Int64}} with 25 entries:\n",
       "  5  => (1, 5)\n",
       "  16 => (4, 1)\n",
       "  20 => (4, 5)\n",
       "  12 => (3, 2)\n",
       "  24 => (5, 4)\n",
       "  8  => (2, 3)\n",
       "  17 => (4, 2)\n",
       "  1  => (1, 1)\n",
       "  19 => (4, 4)\n",
       "  22 => (5, 2)\n",
       "  23 => (5, 3)\n",
       "  6  => (2, 1)\n",
       "  11 => (3, 1)\n",
       "  9  => (2, 4)\n",
       "  14 => (3, 4)\n",
       "  3  => (1, 3)\n",
       "  7  => (2, 2)\n",
       "  25 => (5, 5)\n",
       "  4  => (1, 4)\n",
       "  13 => (3, 3)\n",
       "  15 => (3, 5)\n",
       "  2  => (1, 2)\n",
       "  10 => (2, 5)\n",
       "  18 => (4, 3)\n",
       "  21 => (5, 1)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "world.coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8d4fbd99-9eb9-4c8c-a245-e6bc7151b8e2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{Tuple{Int64, Int64}, Int64} with 25 entries:\n",
       "  (4, 5) => 20\n",
       "  (1, 2) => 2\n",
       "  (3, 1) => 11\n",
       "  (2, 5) => 10\n",
       "  (1, 3) => 3\n",
       "  (1, 4) => 4\n",
       "  (5, 5) => 25\n",
       "  (3, 2) => 12\n",
       "  (3, 3) => 13\n",
       "  (4, 1) => 16\n",
       "  (2, 1) => 6\n",
       "  (3, 4) => 14\n",
       "  (1, 5) => 5\n",
       "  (4, 2) => 17\n",
       "  (5, 1) => 21\n",
       "  (2, 2) => 7\n",
       "  (4, 3) => 18\n",
       "  (2, 3) => 8\n",
       "  (3, 5) => 15\n",
       "  (4, 4) => 19\n",
       "  (2, 4) => 9\n",
       "  (1, 1) => 1\n",
       "  (5, 2) => 22\n",
       "  (5, 3) => 23\n",
       "  (5, 4) => 24"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "world.states"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0ed737-187b-4c88-88e4-dcca9d79e66a",
   "metadata": {},
   "source": [
    "## Task 2: Generate the components of the MDP problem\n",
    "The MDP problem requires the return function (or array) `R(s, a)`, and the transition function (or array) `T(s, s‚Ä≤, a)`. Let's construct these from our grid world model instance, starting with the reward function `R(s, a)`:\n",
    "\n",
    "### Rewards $R(s,a)$\n",
    "We'll encode the reward function as a $\\dim\\mathcal{S}\\times\\dim\\mathcal{A}$ array, which holds the reward values for being in state $s\\in\\mathcal{S}$ and taking action $a\\in\\mathcal{A}$. After initializing the `R`-array and filling it with zeros, we'll populate the non-zero values of $R(s, a)$ using nested `for` loops. During each iteration of the `outer` loop, we'll:\n",
    "* Select a state `s`, an action `a`, and a move `Œî`\n",
    "* We'll then compute the new position resulting from implementing action `a` from the current position and store this in the `new_position` variable. * If the `new_position`$\\in\\mathcal{S}$ is in our initial `rewards` dictionary (the charging station or a lava pit), we use that reward value from the `rewards` dictionary. If we are still in the world but not in a special location, we set the reward to `-1`.\n",
    "* Finally, if `new_position`$\\notin\\mathcal{S}$, i.e., the `new_position` is a space outside the grid, we set a penalty of `-50000.0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f51634b4-76cf-4533-81d2-60e1470117dd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25√ó4 Matrix{Float64}:\n",
       " -50000.0      -1.0  -50000.0   -1000.0\n",
       " -50000.0   -1000.0      -1.0      -1.0\n",
       " -50000.0   -1000.0   -1000.0      -1.0\n",
       " -50000.0      -1.0      -1.0      -1.0\n",
       " -50000.0      -1.0      -1.0  -50000.0\n",
       "     -1.0      -1.0  -50000.0   -1000.0\n",
       "  -1000.0      -1.0      -1.0   -1000.0\n",
       "     -1.0      -1.0   -1000.0      -1.0\n",
       "     -1.0      -1.0   -1000.0      -1.0\n",
       "     -1.0      -1.0      -1.0  -50000.0\n",
       "     -1.0      -1.0  -50000.0      -1.0\n",
       "  -1000.0      -1.0      -1.0      -1.0\n",
       "  -1000.0     100.0      -1.0      -1.0\n",
       "     -1.0      -1.0      -1.0      -1.0\n",
       "     -1.0   -1000.0      -1.0  -50000.0\n",
       "     -1.0      -1.0  -50000.0      -1.0\n",
       "     -1.0      -1.0      -1.0     100.0\n",
       "     -1.0      -1.0      -1.0      -1.0\n",
       "     -1.0      -1.0     100.0   -1000.0\n",
       "     -1.0      -1.0      -1.0  -50000.0\n",
       "     -1.0  -50000.0  -50000.0      -1.0\n",
       "     -1.0  -50000.0      -1.0      -1.0\n",
       "    100.0  -50000.0      -1.0      -1.0\n",
       "     -1.0  -50000.0      -1.0      -1.0\n",
       "  -1000.0  -50000.0      -1.0  -50000.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R = zeros(nstates, nactions);\n",
    "fill!(R, 0.0)\n",
    "for s ‚àà ùíÆ\n",
    "    for a ‚àà ùíú\n",
    "        \n",
    "        Œî = world.moves[a];\n",
    "        current_position = world.coordinates[s]\n",
    "        new_position =  current_position .+ Œî\n",
    "        if (haskey(world.states, new_position) == true)\n",
    "            if (haskey(rewards, new_position) == true)\n",
    "                R[s,a] = rewards[new_position];\n",
    "            else\n",
    "                R[s,a] = -1.0;\n",
    "            end\n",
    "        else\n",
    "            R[s,a] = -50000.0; # we are off the grid, big negative penalty\n",
    "        end\n",
    "    end\n",
    "end\n",
    "R"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40727829-a6d9-446a-8384-83828d967028",
   "metadata": {},
   "source": [
    "### Transition $T(s, s^{\\prime},a)$\n",
    "Next, build the transition function $T(s,s^{\\prime},a)$. We'll encode this as a $\\dim\\mathcal{S}\\times\\dim\\mathcal{S}\\times\\dim\\mathcal{A}$ [multidimension array](https://docs.julialang.org/en/v1/manual/arrays/) and populate it using nested `for` loops. \n",
    "\n",
    "* The `outer` loop we will iterate over actions. For every $a\\in\\mathcal{A}$ will get the move associated with that action and store it in the `Œî`\n",
    "* In the `inner` loop, we will iterate over states $s\\in\\mathcal{S}$. We compute a `new_position` resulting from implementing action $a$ and check if `new_position`$\\in\\mathcal{S}$. If `new_position` is in the world, and `current_position` is _not_ an `absorbing state` we set $s^{\\prime}\\leftarrow$`world.states[new_position]`, and `T[s, s‚Ä≤,  a] = 1.0`\n",
    "* However, if the `new_position` is outside of the grid (or we are jumping from an `absorbing` state), we set `T[s, s,  a] = 1.0`, i.e., the probability that we stay in `s` if we take action `a` is `1.0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13d92d6f-fcd5-44be-acc3-58a275d2987e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "T = Array{Float64,3}(undef, nstates, nstates, nactions);\n",
    "fill!(T, 0.0)\n",
    "for a ‚àà ùíú\n",
    "    \n",
    "    Œî = world.moves[a];\n",
    "    \n",
    "    for s ‚àà ùíÆ\n",
    "        current_position = world.coordinates[s]\n",
    "        new_position =  current_position .+ Œî\n",
    "        if (haskey(world.states, new_position) == true && \n",
    "                in(current_position, absorbing_state_set) == false)\n",
    "            s‚Ä≤ = world.states[new_position];\n",
    "            T[s, s‚Ä≤,  a] = 1.0\n",
    "        else\n",
    "            T[s, s,  a] = 1.0\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c291884-62b4-4b4b-8646-ff5fb0b7447a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(T[24,:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f983f3d-753a-4e5a-92f5-52f941a4d53a",
   "metadata": {},
   "source": [
    "Finally, we construct an instance of the `MyMDPProblemModel` which encodes the data required to solve the MDP problem.\n",
    "* We must pass the states `ùíÆ`, the actions `ùíú`, the transition matrix `T`, the reward matrix `R`, and the discount factor `Œ≥` into the `build(...)` method. We store the MDP model in the `m` variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef79abec-c27e-49ac-acf4-be56211c3f58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "m = build(MyMDPProblemModel, (ùíÆ = ùíÆ, ùíú = ùíú, T = T, R = R, Œ≥ = Œ≥));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b0d40706-61bf-4927-8b0a-8fa54a829c36",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25-element Vector{Int64}:\n",
       "  1\n",
       "  2\n",
       "  3\n",
       "  4\n",
       "  5\n",
       "  6\n",
       "  7\n",
       "  8\n",
       "  9\n",
       " 10\n",
       " 11\n",
       " 12\n",
       " 13\n",
       " 14\n",
       " 15\n",
       " 16\n",
       " 17\n",
       " 18\n",
       " 19\n",
       " 20\n",
       " 21\n",
       " 22\n",
       " 23\n",
       " 24\n",
       " 25"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.ùíÆ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4044aa-b380-4a8c-9252-eae71914e1e3",
   "metadata": {},
   "source": [
    "## Task 3: Estimate the optimal value function $U^{\\star}(s)$\n",
    "Let's explore value iteration by first constructing an instance of the `MyValueIterationModel` type, which takes the maximum number of iterations as a parameter. Save this in the `value_iteration_model` variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c50a8314-d55e-4f0c-981b-f7a406843ca0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "value_iteration_model = MyValueIterationModel(1000);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1629357-940e-4570-a267-8f978426e82a",
   "metadata": {},
   "source": [
    "Next, we call the `solve(...)` method by passing the `value_iteration_model` instance and our MDP model `m::MyMDPProblemModel` as arguments. The `solve(...)` method iteratively computes the value function $U^{\\star}(s)$, by calling the `backup(...)` function, which in turn calls the `lookahead(...)` function:\n",
    "* The `solve(...)` method iteratively computes the optimal value function $U^{\\star}(s)$ and returns it in an instance of the `MyValueFunctionPolicy` type. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3b9b5bc5-d9a3-48c1-8eac-13cb595feea4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "solution = solve(value_iteration_model, m);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ea3eca1a-d9b8-4a10-b7bf-fde455b51347",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25-element Vector{Float64}:\n",
       "  62.26513125000004\n",
       " -19.99999999999995\n",
       "  62.26513125000004\n",
       "  66.59487500000004\n",
       "  62.26513125000004\n",
       "  66.59487500000004\n",
       " -19.99999999999995\n",
       " -19.99999999999995\n",
       "  71.15250000000005\n",
       "  66.59487500000004\n",
       "  71.15250000000005\n",
       "  75.95000000000005\n",
       "  81.00000000000006\n",
       "  75.95000000000005\n",
       "  71.15250000000005\n",
       "  75.95000000000005\n",
       "  81.00000000000006\n",
       " -19.99999999999995\n",
       "  81.00000000000006\n",
       " -19.99999999999995\n",
       "  71.15250000000005\n",
       "  75.95000000000005\n",
       "  81.00000000000006\n",
       "  75.95000000000005\n",
       "  71.15250000000005"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solution.U"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f318f4-c389-49b5-8d46-08e1df83e58f",
   "metadata": {},
   "source": [
    "### Questions\n",
    "* `TODO`: Extract the `action-value function` or $Q(s, a)$ from the optimal optimal value function $U^{\\star}(s)$. We can do this using the `Q(...)` function, which takes `m` and the `solution::MyValueFunctionPolicy`\n",
    "    \n",
    "    ```julia\n",
    "    function Q(p::MyMDPProblemModel, U::Array{Float64,1})::Array{Float64,2}\n",
    "\n",
    "        # grab stuff from the problem\n",
    "        ùíÆ, T, R, Œ≥ = p.ùíÆ, p.T, p.R, p.Œ≥;\n",
    "\n",
    "        # initialize -\n",
    "        Q_array = Array{Float64,2}(undef, length(ùíÆ), length(ùíú))\n",
    "\n",
    "        for s ‚àà 1:length(ùíÆ)\n",
    "            for a ‚àà 1:length(ùíú)\n",
    "                Q_array[s,a] = R[s,a] + Œ≥*sum([T[s, s‚Ä≤,a]*U[s‚Ä≤] for s‚Ä≤ in ùíÆ]);\n",
    "            end\n",
    "        end\n",
    "\n",
    "        return Q_array\n",
    "    end\n",
    "    ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0b7e1e12-f637-4ecb-af32-cd0b3fd56fdb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25√ó4 Matrix{Float64}:\n",
       " -49940.8         62.2651  -49940.8      -1019.0\n",
       " -50019.0      -1019.0        -20.0        -20.0\n",
       " -49940.8      -1019.0      -1019.0         62.2651\n",
       " -49936.7         66.5949      58.1519      58.1519\n",
       " -49940.8         62.2651      62.2651  -49940.8\n",
       "     58.1519      66.5949  -49936.7      -1019.0\n",
       "  -1019.0        -20.0        -20.0      -1019.0\n",
       "    -20.0        -20.0      -1019.0        -20.0\n",
       "     62.2651      71.1525   -1019.0         62.2651\n",
       "     58.1519      66.5949      66.5949  -49936.7\n",
       "     62.2651      71.1525  -49932.4         71.1525\n",
       "  -1019.0         75.95        66.5949      75.95\n",
       "  -1019.0         81.0         71.1525      71.1525\n",
       "     66.5949      75.95        75.95        66.5949\n",
       "     62.2651   -1019.0         71.1525  -49932.4\n",
       "     66.5949      66.5949  -49927.8         75.95\n",
       "     71.1525      71.1525      71.1525      81.0\n",
       "    -20.0        -20.0        -20.0        -20.0\n",
       "     71.1525      71.1525      81.0      -1019.0\n",
       "    -20.0        -20.0        -20.0     -50019.0\n",
       "     71.1525  -49932.4     -49932.4         71.1525\n",
       "     75.95    -49927.8         66.5949      75.95\n",
       "     81.0     -49923.1         71.1525      71.1525\n",
       "     75.95    -49927.8         75.95        66.5949\n",
       "  -1019.0     -49932.4         71.1525  -49932.4"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_Q = Q(m, solution.U)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76fc0626-8041-40e9-b92d-491b6edfe9dd",
   "metadata": {},
   "source": [
    " * `TODO`: Compute the optimal navigation policy $\\pi^{\\star}(s)$ from $Q(s,a)$. We can do this using the `policy(...)` function:\n",
    " ```julia\n",
    " function policy(Q_array::Array{Float64,2})::Array{Int64,1}\n",
    "\n",
    "    # get the dimension -\n",
    "    (NR, _) = size(Q_array);\n",
    "\n",
    "    # initialize some storage -\n",
    "    œÄ_array = Array{Int64,1}(undef, NR)\n",
    "    for s ‚àà 1:NR\n",
    "        œÄ_array[s] = argmax(Q_array[s,:]);\n",
    "    end\n",
    "\n",
    "    # return -\n",
    "    return œÄ_array;\n",
    "end\n",
    " ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e41ba794-1995-48d1-95d5-5aceefbafbab",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25-element Vector{Int64}:\n",
       " 2\n",
       " 3\n",
       " 4\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 1\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 3\n",
       " 4\n",
       " 4\n",
       " 1\n",
       " 3\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 3"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_œÄ = policy(my_Q)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1fcde3-b949-4469-ad96-d51f978a28a8",
   "metadata": {},
   "source": [
    " * `TODO`: Visualize the optimal policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9433b845-d226-4501-9d19-ea4b34efb1e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "move_arrows = Dict{Int,Any}();\n",
    "move_arrows[1] = \"‚Üê\"\n",
    "move_arrows[2] = \"‚Üí\"\n",
    "move_arrows[3] = \"‚Üì\"\n",
    "move_arrows[4] = \"‚Üë\"\n",
    "move_arrows[5] = \"‚àÖ\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9aa4ef98-b525-49ca-a414-826122781e4e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1) ‚Üí (2, 1)\n",
      "(1, 2) ‚àÖ\n",
      "(1, 3) ‚Üë (1, 4)\n",
      "(1, 4) ‚Üí (2, 4)\n",
      "(1, 5) ‚Üí (2, 5)\n",
      "(2, 1) ‚Üí (3, 1)\n",
      "(2, 2) ‚àÖ\n",
      "(2, 3) ‚àÖ\n",
      "(2, 4) ‚Üí (3, 4)\n",
      "(2, 5) ‚Üí (3, 5)\n",
      "(3, 1) ‚Üí (4, 1)\n",
      "(3, 2) ‚Üí (4, 2)\n",
      "(3, 3) ‚Üí (4, 3)\n",
      "(3, 4) ‚Üí (4, 4)\n",
      "(3, 5) ‚Üì (3, 4)\n",
      "(4, 1) ‚Üë (4, 2)\n",
      "(4, 2) ‚Üë (4, 3)\n",
      "(4, 3) ‚àÖ\n",
      "(4, 4) ‚Üì (4, 3)\n",
      "(4, 5) ‚àÖ\n",
      "(5, 1) ‚Üê (4, 1)\n",
      "(5, 2) ‚Üê (4, 2)\n",
      "(5, 3) ‚Üê (4, 3)\n",
      "(5, 4) ‚Üê (4, 4)\n",
      "(5, 5) ‚Üì (5, 4)\n"
     ]
    }
   ],
   "source": [
    "for s ‚àà ùíÆ\n",
    "    a = my_œÄ[s];\n",
    "    Œî = world.moves[a];\n",
    "    current_position = world.coordinates[s]\n",
    "    new_position =  current_position .+ Œî\n",
    "    \n",
    "    if (in(current_position, absorbing_state_set) == true)\n",
    "        println(\"$(current_position) $(move_arrows[5])\")\n",
    "    else\n",
    "        println(\"$(current_position) $(move_arrows[a]) $(new_position)\")\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a97547-498c-4d8a-be5c-e5d92df5d1ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "79a90487-38cc-43e3-9292-f3e651784878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(s, s_next) = ((1, 1), (2, 1))\n",
      "(s, s_next) = ((2, 1), (3, 1))\n",
      "(s, s_next) = ((3, 1), (4, 1))\n",
      "(s, s_next) = ((4, 1), (4, 2))\n",
      "(s, s_next) = ((4, 2), (4, 3))\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlgAAAGQCAIAAAD9V4nPAAAABmJLR0QA/wD/AP+gvaeTAAAOIUlEQVR4nO3cXYxc9X3H4TMza88u3rUx6/CiQoRtsFMaBxd8UWLTJqUqtBaxxUsgdtqUKIpEEKi9oFJ7U6mpqkitqKIoBQqiaoAAdgUSaUp4a4iQwcSNYiwZ4QBNIBicGIO9XrPeednTiwkRvWFtMbtn3e/zXI2Pzv73Jx3+/sw5M6ZWlmUBAKnqVQ8AAFUSQgCiCSEA0YQQgGhCCEA0IQQgmhACEE0IAYgmhABEE0IAop0AIWy321WPkG5qaqrb7VY9RToboXJlWdoIlZuJjXAChPDo0aNVj5Cu0+l0Op2qp0hnI1Su2+22Wq2qp0g3ExvhBAghAMwcIQQgmhACEE0IAYgmhABEE0IA5rqyLO+6657lyy9avvxTZ5655sYb/3p8fLxfiw/0ayEAmCE33PBX9957aGzs0aJYWBRTd9xx15NP/tHzz//XvHnzPvzi7ggBmNPeeOONrVu3jY3dWhQLi6Ioivrk5JdeffWSu+++ry/rV3BHODU1dVz/a4DJycn58+fP3DxMq9VqlWVZ9RTpbITKdTqddrtdr7t/mG3PPPPMxMQf9F5//OO7X3xxZacz8O6767/znTs2b77mg3923rx5016yCq5orVab/V8KwImrVvvVe/GyrBVFLyJlvd6fmlRwR1ir1ZrN5rGf32q1jut8+q5Wq5Vl6SpUy0aoXKPRqNfrrsLsW7du3eDgP42P/01R1HbvPq93cMGC/9iw4Xf7cjnc4wMwp51++umbNv3+okVfKop3iqIoiu7g4D8vXfqDTZumeS56jIQQgLnu61//6je/eem5515+2mlrPvrRi264Yf9zzz0yMNCfh5q1uf8liMOHD4+MjFQ9RbTel2U8EaqWjVC53pdlhoaGqh4k2kxsBHeEAEQTQgCiCSEA0YQQgGhCCEA0IQQgmhACEE0IAYgmhABEE0IAogkhANGEEIBoQghANCEEIJoQAhBNCAGIJoQARBNCAKIJIQDRhBCAaEIIQDQhBCCaEAIQTQgBiCaEAEQTQgCiCSEA0YQQgGhCCEA0IQQgmhACEE0IAYgmhABEE0IAogkhANGEEIBoQghANCEEIJoQAhBNCAGIJoQARBNCAKIJIQDRhBCAaEIIQDQhBCCaEAIQTQgBiCaEAEQTQgCiCSEA0YQQgGhCCEA0IQQgmhACEE0IAYgmhABEE0IAogkhANGEEIBoQghANCEEIJoQAhBNCAGIJoQARBNCAKIJIQDRhBCAaEIIQDQhBCCaEAIQTQgBiCaEAEQTQgCiCSEA0YQQgGhCCEA0IQQgmhACEG1g9n9lt9udnJw89vMnJiYajcbMzcO0Wq1WWZbdbrfqQaLZCJXrdDrtdrssy6oHiXa8G2H+/PkDA9OUroIQNhqNZrN57Oe3Wq3jOp++q9VqZVm6CtWyESrXaDTq9bqrUK3j3Qj1+vQPPisIYVEUx9XzRqPhjXC1Go1GWZauQrVshMqVZTk1NeUqVGsmNoLPCAGIJoQARBNCAKIJIQDRhBCAaEIIQDQhBCCaEAIQTQgBiCaEAEQTQgCiCSEA0YQQgGhCCEA0IQQgmhACEE0IAYgmhABEE0IAogkhANGEEIBoQghANCEEIJoQAhBNCAGIJoQARBNCAKIJIQDRhBCAaEIIQDQhBCCaEAIQTQgBiCaEAEQTQgCiCSEA0YQQgGhCCEA0IQQgmhACEE0IAYgmhABEE0IAogkhANGEEIBoQghANCEEIJoQAhBNCAGIJoQARBNCAKIJIQDRhBCAaEIIQDQhBCCaEAIQTQgBiCaEAEQTQgCiCSEA0YQQgGhCCEA0IQQgmhACEE0IAYgmhABEE0IAogkhANGEEIBoQghANCEEIJoQAhBNCAGIJoQARBNCAKIJIQDRhBCAaEIIQDQhBODEsG/fvm3btr300ktTU1N9XHagj2sBwEx4++23N2++8Uc/2tfpnD9v3t6TT37929/+xoUXXtCXxYUQgLnu0ks/9+Mff6Xb3dD74y9/+cr69Vft2vXoqaee+uEX92gUgDlt165dP/vZyb+uYFEURbH8rbduuu22f+vL+hXcEXa73YmJiWM//8iRI7VabebmYVqtVqssy3a7XfUg0WyEynU6nXa73e12qx4kzq5du44cWd17fdlljz711KeOHm12uxdu337L+Pj4B//s4ODgwMA0pasghI1GY3h4+NjPL8vyuM6n73ohbDabVQ8SzUaoXC+EQ0NDVQ8S57TTTms2d/ZuoJ555qKjR3t/F+0//fTRvmwKj0YBmNPWrl3bbD5ZFAeLohgbW9g7uHjxbdddt7Ev6wshAHPaSSeddNttX/3IR/6wVvv3oni5KH4wOrrxs59ddvHFF/dl/VpZln1ZaOYcPnx4ZGSk6imieTQ6F9gIlfNotFp79+695ZZ/2bHjhWXLzvryl6/+5Ccv6tfKQsj0hHAusBEqJ4RzwUxsBI9GAYgmhABEE0IAogkhANGEEIBoQghANCEEIJoQAhBNCAGIJoQARBNCAKIJIQDRhBCAaEIIQDQhBCCaEAIQTQgBiCaEAEQTQgCiCSEA0YQQgGhCCEA0IQQgmhACEE0IAYgmhABEE0IAogkhANGEEIBoQghANCEEIJoQAhBNCAGIJoQARBNCAKIJIQDRhBCAaEIIQDQhBCCaEAIQTQgBiCaEAEQTQgCiCSEA0YQQgGhCCEA0IQQgmhACEE0IAYgmhABEE0IAogkhANGEEIBoQghANCEEIJoQAhBNCAGIJoQARBNCAKIJIQDRhBCAaEIIQDQhBCCaEAIQTQgBiCaEAEQTQgCiCSEA0YQQgGhCCEA0IQQgmhACEE0IAYgmhABEE0IAogkhANGEEIBoQghANCEEINrA7P/Kbrc7MTFx7OcfOXKkVqvN3DxMq9VqlWXZbrerHiSajVC5TqfTbre73W7Vg0Q73o0wODg4MDBN6SoIYaPRGB4ePvbzy7I8rvPpu14Im81m1YNEsxEq1wvh0NBQ1YNEm4mN4NEoANGEEIBoQghANCEEIJoQAhBNCAGIJoQARBNCAKIJIQDRhBCAaEIIQDQhBCCaEAIQTQgBiCaEAEQTQgCiCSEA0YQQgGhCCEA0IQQgmhACEE0IAYgmhABEE0IAogkhANGEEIBoQghANCEEIJoQAhBNCAGIJoQARBNCAKIJIQDRhBCAaEIIQDQhBCCaEAIQTQgBiCaEAEQTQgCiCSEA0YQQgGhCCEA0IQQgmhACEE0IAYgmhABEE0IAogkhANGEEIBoQghANCEEIJoQAhBNCAGIJoQARBNCAKIJIQDRhBCAaEIIQDQhBCCaEAIQTQgBiCaEAEQTQgCiCSEA0YQQgGhCCEA0IQQgmhACEE0IAYgmhABEE0IAogkhANGEEIBoQghANCEEIJoQAhBNCAGIJoQARBuoeoAPsn///i1bHty58+ULLjj3mmuuOuWUU6qeCCpw6NChBx7YumPHnk98YtlVV20844wzqp4IKvDuu+8+8MDW7dt3r1x51hVXXH722Wf3a+VaWZb9Wqu/tmx56Kab/v7AgS92OucMDOwZHf3X22//2w0b1lc9V6JWq1WWZbPZrHqQRI899uQXvvCXBw78abt9Xr3+0yVL7vza1/78uus2VT1Xok6n0263h4aGqh4k0XPP/fDKK69/661rJyfPr9X2Lllyx803f/7mm7/Sl8XnaAjffPPN88//zP793y+K4feOHTr11E+/8MLjo6OjVU4WSQirMjY2tmLF7/3iF08Uxa//s59YsuTTO3bc38e3wxwjIaxKq9Vatux39u59uCjOfO9YZ3T0siee+MfVq1d/+PXn6GeEDz748MGDf9arYKPRLYqiKBYdOrT5u9/9z0rngln1+OOPj49v7FXwvY0w9M47199//0PVDgaz6dlnn52YWNur4HsbYeDAgb+4884tfVm/gs8Iu93uxMTEB5/zyiuvt9treq83bbrv7rs/XxTF5OSZL7308vj4+IyPyP/VuyNst9tVDxLn1Vd/fuTIr94CX3vt/ffd97mpqXq3e+ZPfvK8jTD7eneE3W636kHivPbaaxMTv9F7feWVDz788GeOHm0WxVmvvLJ32o0wODg4MDBN6SoIYaPRGB4e/uBzVq06d3Bwz9GjRVEUvQoWRbFgwZ5Vq35z2p+l7zwarcrHPrZi4cKnxsaKoijuvXdz7+C8eXtWrz7XRph9Ho1WZeXKlSed9P3eDdSWLVf3DtZqe1atWt6XjTBHH41eccWGk0++ryh+/r5j/7No0UPr1/9xZTPBrLvkkksWLXqyKF5837F9ixffsWnT1ZXNBLNuzZo1o6MvFsV/v+/YwdHRf7j++j/py/pz9J9PLFq06KGHbr/22ivHxtaOjZ2zcOGexYt/uHXrXQsWLKh6NJg9zWbzkUe+tXHjF99+e/WhQ781MvLTkZGn7rnnG0uWLKl6NJg99Xr9e9+79/LLr9u375yDB397ePj1BQseu/XWv1u6dGlf1p+j3xrtabfbTz/99J49e84777y1a9dO+5yXGeLRaLW63e62bdt27969YsWKdevWuRBV8Wi0WmVZbt++fefOncuXL1+7dm0f74vmdAh7Dh8+PDIyUvUU0YRwLrARKieEc8FMbIQ5+hkhAMwOIQQgmhACEE0IAYh2AnwPs9FoVD1Cunq9Pve/VPX/no1QuVqtVq+7eajYTGyEE+BbowAwc7y7ASCaEAIQTQgBiCaEAEQTQgCiCSEA0YQQgGhCCEA0IQQgmhACEE0IAYgmhABEE0IAogkhANGEEIBoQghANCEEIJoQAhBNCAGIJoQARBNCAKIJIQDRhBCAaEIIQDQhBCCaEAIQTQgBiPa/8aRU5Jo97KUAAAAASUVORK5CYII=",
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"600\" height=\"400\" viewBox=\"0 0 2400 1600\">\n",
       "<defs>\n",
       "  <clipPath id=\"clip780\">\n",
       "    <rect x=\"0\" y=\"0\" width=\"2400\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip780)\" d=\"M0 1600 L2400 1600 L2400 8.88178e-14 L0 8.88178e-14  Z\" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip781\">\n",
       "    <rect x=\"480\" y=\"0\" width=\"1681\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip780)\" d=\"M155.765 1486.45 L2352.76 1486.45 L2352.76 47.2441 L155.765 47.2441  Z\" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip782\">\n",
       "    <rect x=\"155\" y=\"47\" width=\"2198\" height=\"1440\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<polyline clip-path=\"url(#clip782)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"217.944,1486.45 217.944,47.2441 \"/>\n",
       "<polyline clip-path=\"url(#clip782)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"736.102,1486.45 736.102,47.2441 \"/>\n",
       "<polyline clip-path=\"url(#clip782)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"1254.26,1486.45 1254.26,47.2441 \"/>\n",
       "<polyline clip-path=\"url(#clip782)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"1772.42,1486.45 1772.42,47.2441 \"/>\n",
       "<polyline clip-path=\"url(#clip782)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"2290.58,1486.45 2290.58,47.2441 \"/>\n",
       "<polyline clip-path=\"url(#clip782)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"155.765,1445.72 2352.76,1445.72 \"/>\n",
       "<polyline clip-path=\"url(#clip782)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"155.765,1106.28 2352.76,1106.28 \"/>\n",
       "<polyline clip-path=\"url(#clip782)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"155.765,766.846 2352.76,766.846 \"/>\n",
       "<polyline clip-path=\"url(#clip782)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"155.765,427.411 2352.76,427.411 \"/>\n",
       "<polyline clip-path=\"url(#clip782)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"155.765,87.9763 2352.76,87.9763 \"/>\n",
       "<circle clip-path=\"url(#clip782)\" cx=\"217.944\" cy=\"1445.72\" r=\"14.4\" fill=\"#0000ff\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<polyline clip-path=\"url(#clip782)\" style=\"stroke:#808080; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"217.944,1445.72 217.944,1445.72 \"/>\n",
       "<polyline clip-path=\"url(#clip782)\" style=\"stroke:#808080; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"nan,nan nan,nan nan,nan \"/>\n",
       "<polyline clip-path=\"url(#clip782)\" style=\"stroke:#808080; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"nan,nan nan,nan \"/>\n",
       "<circle clip-path=\"url(#clip782)\" cx=\"1254.26\" cy=\"1445.72\" r=\"14.4\" fill=\"#0000ff\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<polyline clip-path=\"url(#clip782)\" style=\"stroke:#808080; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"1254.26,1445.72 1254.26,1445.72 \"/>\n",
       "<polyline clip-path=\"url(#clip782)\" style=\"stroke:#808080; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"nan,nan nan,nan nan,nan \"/>\n",
       "<polyline clip-path=\"url(#clip782)\" style=\"stroke:#808080; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"nan,nan nan,nan \"/>\n",
       "<circle clip-path=\"url(#clip782)\" cx=\"2290.58\" cy=\"1445.72\" r=\"14.4\" fill=\"#0000ff\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<polyline clip-path=\"url(#clip782)\" style=\"stroke:#808080; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"2290.58,1445.72 2290.58,1445.72 \"/>\n",
       "<polyline clip-path=\"url(#clip782)\" style=\"stroke:#808080; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"nan,nan nan,nan nan,nan \"/>\n",
       "<polyline clip-path=\"url(#clip782)\" style=\"stroke:#808080; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"nan,nan nan,nan \"/>\n",
       "<circle clip-path=\"url(#clip782)\" cx=\"2290.58\" cy=\"766.846\" r=\"14.4\" fill=\"#0000ff\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<polyline clip-path=\"url(#clip782)\" style=\"stroke:#808080; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"2290.58,766.846 2290.58,766.846 \"/>\n",
       "<polyline clip-path=\"url(#clip782)\" style=\"stroke:#808080; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"nan,nan nan,nan nan,nan \"/>\n",
       "<polyline clip-path=\"url(#clip782)\" style=\"stroke:#808080; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"nan,nan nan,nan \"/>\n",
       "<circle clip-path=\"url(#clip782)\" cx=\"2290.58\" cy=\"87.9763\" r=\"14.4\" fill=\"#0000ff\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<polyline clip-path=\"url(#clip782)\" style=\"stroke:#808080; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"2290.58,87.9763 2290.58,87.9763 \"/>\n",
       "<polyline clip-path=\"url(#clip782)\" style=\"stroke:#808080; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"nan,nan nan,nan nan,nan \"/>\n",
       "<polyline clip-path=\"url(#clip782)\" style=\"stroke:#808080; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"nan,nan nan,nan \"/>\n",
       "</svg>\n"
      ],
      "text/html": [
       "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"600\" height=\"400\" viewBox=\"0 0 2400 1600\">\n",
       "<defs>\n",
       "  <clipPath id=\"clip830\">\n",
       "    <rect x=\"0\" y=\"0\" width=\"2400\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip830)\" d=\"M0 1600 L2400 1600 L2400 8.88178e-14 L0 8.88178e-14  Z\" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip831\">\n",
       "    <rect x=\"480\" y=\"0\" width=\"1681\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip830)\" d=\"M155.765 1486.45 L2352.76 1486.45 L2352.76 47.2441 L155.765 47.2441  Z\" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip832\">\n",
       "    <rect x=\"155\" y=\"47\" width=\"2198\" height=\"1440\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<polyline clip-path=\"url(#clip832)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"217.944,1486.45 217.944,47.2441 \"/>\n",
       "<polyline clip-path=\"url(#clip832)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"736.102,1486.45 736.102,47.2441 \"/>\n",
       "<polyline clip-path=\"url(#clip832)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"1254.26,1486.45 1254.26,47.2441 \"/>\n",
       "<polyline clip-path=\"url(#clip832)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"1772.42,1486.45 1772.42,47.2441 \"/>\n",
       "<polyline clip-path=\"url(#clip832)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"2290.58,1486.45 2290.58,47.2441 \"/>\n",
       "<polyline clip-path=\"url(#clip832)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"155.765,1445.72 2352.76,1445.72 \"/>\n",
       "<polyline clip-path=\"url(#clip832)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"155.765,1106.28 2352.76,1106.28 \"/>\n",
       "<polyline clip-path=\"url(#clip832)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"155.765,766.846 2352.76,766.846 \"/>\n",
       "<polyline clip-path=\"url(#clip832)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"155.765,427.411 2352.76,427.411 \"/>\n",
       "<polyline clip-path=\"url(#clip832)\" style=\"stroke:#000000; stroke-linecap:round; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"155.765,87.9763 2352.76,87.9763 \"/>\n",
       "<circle clip-path=\"url(#clip832)\" cx=\"217.944\" cy=\"1445.72\" r=\"14.4\" fill=\"#0000ff\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<polyline clip-path=\"url(#clip832)\" style=\"stroke:#808080; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"217.944,1445.72 217.944,1445.72 \"/>\n",
       "<polyline clip-path=\"url(#clip832)\" style=\"stroke:#808080; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"nan,nan nan,nan nan,nan \"/>\n",
       "<polyline clip-path=\"url(#clip832)\" style=\"stroke:#808080; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"nan,nan nan,nan \"/>\n",
       "<circle clip-path=\"url(#clip832)\" cx=\"1254.26\" cy=\"1445.72\" r=\"14.4\" fill=\"#0000ff\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<polyline clip-path=\"url(#clip832)\" style=\"stroke:#808080; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"1254.26,1445.72 1254.26,1445.72 \"/>\n",
       "<polyline clip-path=\"url(#clip832)\" style=\"stroke:#808080; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"nan,nan nan,nan nan,nan \"/>\n",
       "<polyline clip-path=\"url(#clip832)\" style=\"stroke:#808080; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"nan,nan nan,nan \"/>\n",
       "<circle clip-path=\"url(#clip832)\" cx=\"2290.58\" cy=\"1445.72\" r=\"14.4\" fill=\"#0000ff\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<polyline clip-path=\"url(#clip832)\" style=\"stroke:#808080; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"2290.58,1445.72 2290.58,1445.72 \"/>\n",
       "<polyline clip-path=\"url(#clip832)\" style=\"stroke:#808080; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"nan,nan nan,nan nan,nan \"/>\n",
       "<polyline clip-path=\"url(#clip832)\" style=\"stroke:#808080; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"nan,nan nan,nan \"/>\n",
       "<circle clip-path=\"url(#clip832)\" cx=\"2290.58\" cy=\"766.846\" r=\"14.4\" fill=\"#0000ff\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<polyline clip-path=\"url(#clip832)\" style=\"stroke:#808080; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"2290.58,766.846 2290.58,766.846 \"/>\n",
       "<polyline clip-path=\"url(#clip832)\" style=\"stroke:#808080; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"nan,nan nan,nan nan,nan \"/>\n",
       "<polyline clip-path=\"url(#clip832)\" style=\"stroke:#808080; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"nan,nan nan,nan \"/>\n",
       "<circle clip-path=\"url(#clip832)\" cx=\"2290.58\" cy=\"87.9763\" r=\"14.4\" fill=\"#0000ff\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<polyline clip-path=\"url(#clip832)\" style=\"stroke:#808080; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"2290.58,87.9763 2290.58,87.9763 \"/>\n",
       "<polyline clip-path=\"url(#clip832)\" style=\"stroke:#808080; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"nan,nan nan,nan nan,nan \"/>\n",
       "<polyline clip-path=\"url(#clip832)\" style=\"stroke:#808080; stroke-linecap:round; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"nan,nan nan,nan \"/>\n",
       "</svg>\n"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# draw the path -\n",
    "p = plot();\n",
    "s = (1,1);\n",
    "\n",
    "visited_sites = Set{Tuple{Int,Int}}();\n",
    "# push!(visited_sites, initial_site);\n",
    "\n",
    "while (in(s, absorbing_state_set) == false)\n",
    "\n",
    "    state = world.states[s];\n",
    "    a = my_œÄ[state];\n",
    "    Œî = world.moves[a];\n",
    "    s_next =  s .+ Œî\n",
    "\n",
    "    @show s, s_next\n",
    "\n",
    "    scatter!([s[1]],[s[2]], label=\"\", showaxis=:false, msc=:black, c=:blue)\n",
    "    plot!([s[1], s_next[1]],[s[2], s_next[2]], label=\"\", arrow=true, lw=1, c=:gray)\n",
    "    \n",
    "    if (haskey(world.states, s_next) == true)\n",
    "        push!(visited_sites, s_next);\n",
    "        s = s_next;\n",
    "    end\n",
    "end\n",
    "\n",
    "# draw the grid -\n",
    "# for s ‚àà ùíÆ\n",
    "#     current_position = world.coordinates[s]\n",
    "#     a = my_œÄ[s];\n",
    "#     Œî = world.moves[a];\n",
    "#     new_position =  current_position .+ Œî\n",
    "    \n",
    "#     if (haskey(rewards, current_position) == true && rewards[current_position] == charging_reward)\n",
    "#         scatter!([current_position[1]],[current_position[2]], label=\"\", showaxis=:false, c=:green, ms=6)\n",
    "#     elseif (haskey(rewards, current_position) == true && rewards[current_position] == lava_reward)\n",
    "#         scatter!([current_position[1]],[current_position[2]], label=\"\", showaxis=:false, c=:red, ms=6)\n",
    "#     else (in(current_position, soft_wall_set) == true)\n",
    "#         scatter!([current_position[1]],[current_position[2]], label=\"\", showaxis=:false, c=:gray69, ms=4)\n",
    "#     end\n",
    "# end\n",
    "current()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b53c1db-86d8-4a3e-abf5-76475ac1f39f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.2",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
