{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf979632-79b3-4c3f-919c-424fd5e3de94",
   "metadata": {},
   "source": [
    "# Example: Learning Linear Regression Parameters using Singular Value Decomposition (SVD)\n",
    "This example will familiarize students with using [Singular Value Decomposition]() to estimate the parameters in ordinary least squares and regularized least squares calculations. In particular, we'll look at estimating the parameters in single-index models for equity returns.\n",
    "\n",
    "### Single index model of Sharpe\n",
    "A single index model describes the return of a firm’s stock in terms of a firm-specific return and the overall market return. One of the simplest (yet still widely used) single index models was developed by [Sharpe (1963)](https://en.wikipedia.org/wiki/Single-index_model#:~:text=The%20single%2Dindex%20model%20(SIM,used%20in%20the%20finance%20industry.)). Let $R_{i}(t)\\equiv\\left(r_{i}\\left(t\\right) - r_{f}\\right)$ \n",
    "and $R_{m}(t)\\equiv\\left(r_{m}\\left(t\\right)-r_{f}\\right)$ denote the firm-specific and market **excess returns**, where $r_{f}$ denotes the risk-free rate of return.\n",
    "Further, let $\\epsilon_{i}\\left(t\\right)$ denote stationary normally distributed random noise\n",
    "with mean zero and standard deviation $\\sigma_{i}$. Then, the single index model of Sharpe is given by:\n",
    "\n",
    "$$\n",
    "\\begin{equation*}\n",
    "R_{i}\\left(t\\right) = \\alpha_{i}+\\beta_{i}\\cdot{R}_{m}\\left(t\\right)+\\epsilon_{i}\n",
    "\\left(t\\right)\\qquad{t=1,2,\\dots,T}\n",
    "\\end{equation*}\n",
    "$$\n",
    "\n",
    "where $\\alpha_{i}$ and $\\beta_{i}$ are (unknown) model parameters: \n",
    "* $\\alpha_{i}$ describes the firm-specific return not explained by the market; thus, $\\alpha_{i}$ is the idiosyncratic return of firm $i$.\n",
    "* $\\beta_{i}$ has two interpretations. First, it measures the relationship between the excess return of firm $i$ and the excess return of the market. \n",
    "A large $\\beta_{i}$ suggests that the market returns (or losses) are amplified for firm $i$, while a small $\\beta_{i}$ suggests that the market returns (or losses) are damped for firm $i$. \n",
    "Second, it represents the relative risk of investing in a firm $i$ relative to the overall market."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07550441-a826-4b35-998b-51638f613375",
   "metadata": {},
   "source": [
    "## Setup\n",
    "This example requires several external libraries and a function to compute the outer product. Let's download and install these packages and call our `Include.jl` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "902e433f-99ee-474a-910a-1d2add60bdca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m git-repo `https://github.com/varnerlab/VLDecisionsPackage.jl.git`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/Desktop/julia_work/CHEME-4800-5800-Examples-AY-2024/week-10/L10c/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/Desktop/julia_work/CHEME-4800-5800-Examples-AY-2024/week-10/L10c/Manifest.toml`\n",
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m project at `~/Desktop/julia_work/CHEME-4800-5800-Examples-AY-2024/week-10/L10c`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/Desktop/julia_work/CHEME-4800-5800-Examples-AY-2024/week-10/L10c/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/Desktop/julia_work/CHEME-4800-5800-Examples-AY-2024/week-10/L10c/Manifest.toml`\n",
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m registry at `~/.julia/registries/General.toml`\n",
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m git-repo `https://github.com/varnerlab/VLDecisionsPackage.jl.git`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/Desktop/julia_work/CHEME-4800-5800-Examples-AY-2024/week-10/L10c/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/Desktop/julia_work/CHEME-4800-5800-Examples-AY-2024/week-10/L10c/Manifest.toml`\n",
      "\u001b[36m\u001b[1m        Info\u001b[22m\u001b[39m We haven't cleaned this depot up for a bit, running Pkg.gc()...\n",
      "\u001b[32m\u001b[1m      Active\u001b[22m\u001b[39m manifest files: 132 found\n",
      "\u001b[32m\u001b[1m      Active\u001b[22m\u001b[39m artifact files: 215 found\n",
      "\u001b[32m\u001b[1m      Active\u001b[22m\u001b[39m scratchspaces: 9 found\n",
      "\u001b[32m\u001b[1m     Deleted\u001b[22m\u001b[39m 26 package installations (6.133 MiB)\n",
      "\u001b[32m\u001b[1m     Deleted\u001b[22m\u001b[39m 2 scratchspaces (4.017 KiB)\n"
     ]
    }
   ],
   "source": [
    "include(\"Include.jl\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb7356d-9e06-4013-8c39-6e7e99f84c3a",
   "metadata": {},
   "source": [
    "## Prerequisites \n",
    "We gathered a daily open-high-low-close `dataset` for each firm in the [S&P500](https://en.wikipedia.org/wiki/S%26P_500) from `01-03-2018` until `03-14-2024`, along with data for a few exchange-traded funds and volatility products during that time. \n",
    "* We load the `orignal_dataset` by calling the `MyPortfolioDataSet()` function and then remove firms that do not have the maximum number of trading days, i.e., they are missing data. We save the cleaned data in the `dataset` variable.\n",
    "* We'll also grab the list of firms in the `dataset` and sort them alphabetically. We'll store the sorted list of firms in the `my_list_of_tickers` dataset.\n",
    "* Finally, we'll compute the excess return matrix `R` and the excess return for the market index, in this case treated as `SPY`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2387321-1570-45fc-bb91-dfd31cd07a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dict{String,DataFrame}();\n",
    "original_dataset = MyPortfolioDataSet() |> x->x[\"dataset\"];\n",
    "maximum_number_trading_days = original_dataset[\"AAPL\"] |> nrow;\n",
    "for (ticker,data) ∈ original_dataset\n",
    "    if (nrow(data) == maximum_number_trading_days)\n",
    "        dataset[ticker] = data;\n",
    "    end\n",
    "end\n",
    "my_list_of_tickers = keys(dataset) |> collect |> x->sort(x);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91ffd4f-ee73-4f70-9998-fef0af3d596b",
   "metadata": {},
   "source": [
    "The single index model uses a market index, e.g., the [S&P500](https://en.wikipedia.org/wiki/S%26P_500), as the base from which we compute the return for firm $i$. Let's get the index in our dataset that corresponds to [SPDR SPY](https://www.ssga.com/us/en/intermediary/etfs/capabilities/spdr-core-equity-etfs/spy-sp-500), an ETF that tracks the [S&P500](https://en.wikipedia.org/wiki/S%26P_500). \n",
    "* We'll use the [findfirst function](https://docs.julialang.org/en/v1/base/strings/#Base.findfirst-Tuple{AbstractString,%20AbstractString}) on the `my_list_of_tickers` list to find the index that corresponds to `SPY`, we'll use this later. We'll store this value in the `idx_spy` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2575057-a9fe-4498-9842-ccb973f6d353",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_spy = findfirst(x->x==\"SPY\", my_list_of_tickers); "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95bf13ad-6b44-49f0-b903-6e5ffe5b1d76",
   "metadata": {},
   "source": [
    "Finally, we must calculate the `excess return` from the price information stored in the `dataset.` We'll do this for every firm in the `dataset` using the `μ(...)` function. We'll store the excess return data in the `R` matrix, and the excess return for `SPY` in the `Rₘ` variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9e73149a-ec13-4ab2-9584-a988dc9b7179",
   "metadata": {},
   "outputs": [],
   "source": [
    "risk_free_rate = 0.05;\n",
    "R = μ(dataset, my_list_of_tickers, risk_free_rate = risk_free_rate) |> x-> transpose(x) |> Matrix;\n",
    "Rₘ = R[idx_spy, :]; # this is the growth rate of the market, which we apoproximate by the SPY ETF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31607a29-5f4b-4623-b407-43d489a3c688",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1557-element Vector{Float64}:\n",
       "  1.5050377454909538\n",
       "  1.095468088086578\n",
       "  0.7757592626051124\n",
       "  0.7390204094703445\n",
       " -0.659217123297486\n",
       "  1.2784386070568685\n",
       "  1.8262837004768115\n",
       "  0.5011457033442471\n",
       "  0.5948732710078719\n",
       "  0.44603924309987253\n",
       "  0.4564092862912787\n",
       "  1.7522322189385078\n",
       "  1.0553224381234976\n",
       "  ⋮\n",
       " -0.4719770170266065\n",
       " -0.14738780347442887\n",
       "  0.8981279176165984\n",
       "  1.5807628608286195\n",
       "  0.6777283645585958\n",
       " -2.4011983851922336\n",
       "  0.9188625992892551\n",
       "  2.087665996949812\n",
       " -0.16219197151137427\n",
       " -1.7062801647597288\n",
       "  2.118848347155344\n",
       "  0.5559387917487099"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Rₘ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac319c7-3d6a-4561-b4c8-f1e6e4195e0e",
   "metadata": {},
   "source": [
    "## Compute $\\theta$ using pseudo-inverse and SVD approaches\n",
    "\n",
    "#### Pseudo inverse approach\n",
    "Regularized least squares estimates of the unknown parameters $\\mathbf{\\beta}$ \\textit{minimize} the sum of squared errors between the model calculated and observed \n",
    "outputs plus a penalty term:\n",
    "\\begin{equation*}\n",
    "\\hat{\\mathbf{\\theta}}_{\\lambda} = \\arg\\min_{\\mathbf{\\theta}} ||~\\mathbf{y} - \\mathbf{X}\\cdot\\mathbf{\\theta}~||^{2}_{2} + \\lambda\\cdot||~\\mathbf{\\theta}~||^{2}_{2}\n",
    "\\end{equation*}\n",
    "where $||\\star||^{2}_{2}$ is the square of the p = 2 vector norm, $\\lambda\\geq{0}$ denotes the regularization parameter, and $\\hat{\\mathbf{\\theta}}$ denotes the estimated parameter vector. \n",
    "The $\\hat{\\mathbf{\\theta}}$ that minimizes the $||\\star||^{2}_{2}$ loss plus penalty for data matrix $\\mathbf{X}$ is given by:\n",
    "\\begin{equation*}\n",
    "\\hat{\\mathbf{\\theta}}_{\\lambda} = \\left(\\mathbf{X}^{T}\\mathbf{X}+\\lambda\\cdot\\mathbf{I}\\right)^{-1}\\mathbf{X}^{T}\\mathbf{y} - \\left(\\mathbf{X}^{T}\\mathbf{X}+\\lambda\\cdot\\mathbf{I}\\right)^{-1}\\mathbf{X}^{T}\\mathbf{\\epsilon}\n",
    "\\end{equation*}\n",
    "The matrix $\\mathbf{X}^{T}\\mathbf{X}+\\lambda\\cdot\\mathbf{I}$ is called the _regularized normal matrix_, while $\\mathbf{X}^{T}\\mathbf{y}$ is called the _moment vector_.\n",
    "The matrix $\\left(\\mathbf{X}^{T}\\mathbf{X}+\\lambda\\cdot\\mathbf{I}\\right)^{-1}$ must exist for the solution $\\hat{\\mathbf{\\theta}}_{\\lambda}$ to exist.\n",
    "\n",
    "#### SVD approach\n",
    "Let the [singular value decomposition (SVD)](https://en.wikipedia.org/wiki/Singular_value_decomposition) of the $n\\times{p}$ data matrix $\\mathbf{X}$ be given by:\n",
    "\\begin{equation}\n",
    "\\mathbf{X} = \\mathbf{U}\\cdot\\mathbf{\\Sigma}\\cdot\\mathbf{V}^{T}\n",
    "\\end{equation}\n",
    "where $\\mathbf{U}$ is an orthogonal matrix, $\\mathbf{\\Sigma}$ is a diagonal singular value matrix,\n",
    "and $\\mathbf{V}$ is an orthogonal matrix. Then, the regularized least-squares estimate of the unknown parameter vector $\\mathbf{\\theta}$ is given by:\n",
    "\\begin{equation}\n",
    "\\hat{\\mathbf{\\theta}}_{\\lambda} = \\Bigl[\\left(\\mathbf{\\Sigma}^{T}\\mathbf{\\Sigma}+\\lambda\\mathbf{I}\\right)\\mathbf{V}^{T}\\Bigr]^{-1}\\cdot\\mathbf{\\Sigma^{T}}\\cdot\\mathbf{U}^{T}\\cdot\\mathbf{y}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4eaf4994-8ca7-48a8-8c0a-07833c89e0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "λ = 0.0;\n",
    "ticker_to_explore = \"IBM\";\n",
    "idx_of_ticker = findfirst(x->x==ticker_to_explore, my_list_of_tickers);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77b13732-df38-4b2a-88cc-a1d96cb98ff8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Vector{Float64}:\n",
       " -0.06439967698961394\n",
       "  0.8938876296406099"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "θ̂_pinv = θ(R,idx_of_ticker, Rₘ, λ = λ, method = MyMatrixAlgebraLearningMethod())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b86ea965-62bc-4552-ba24-58735c3f914d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2-element Vector{Float64}:\n",
       " -0.06439967698961394\n",
       "  0.89388762964061"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "θ̂_svd = θ(R,idx_of_ticker, Rₘ, λ = λ, method = MySVDLearingMethod())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae09650-cef5-4e2a-8205-e75a74df9483",
   "metadata": {},
   "source": [
    "#### Check: Do the two approaches give the same answer?\n",
    "Let's use the [@assert macro](https://docs.julialang.org/en/v1/base/base/#Base.@assert) to check if the parameter vectors `θ̂_pinv` and `θ̂_svd` are `close`. If this test fails, [an AssertionError](https://docs.julialang.org/en/v1/base/base/#Core.AssertionError) is thrown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2c5d14b-0c65-48fb-b958-f9876796d0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "@assert θ̂_pinv ≈ θ̂_svd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1acfbada-744b-43b6-8194-7782bf89b655",
   "metadata": {},
   "source": [
    "## A deeper look at the SVD approach\n",
    "One of the exciting things about using the [singular value decomposition](https://en.wikipedia.org/wiki/Singular_value_decomposition) to solve the linear regression problem for the unknown parameter vector $\\hat{\\theta}_{\\lambda}$ is the summation relationship:\n",
    "$$\n",
    "\\begin{equation*}\n",
    "\\hat{\\theta}_{\\lambda} = \\sum_{i=1}^{r}\\frac{\\sigma_{i}(\\mathbf{u}_{i}^{T}\\cdot\\mathbf{y})}{\\sigma_{i}^{2}+\\lambda}\\cdot\\mathbf{v}_{i}\n",
    "\\end{equation*}\n",
    "$$\n",
    "where $r$ denotes the rank of the data matrix $\\mathbf{X}$, $\\mathbf{u}_{i}$ and $\\mathbf{v}_{i}$ are the $i$-th columns of $\\mathbf{U}$ and $\\mathbf{V}$, respectively, $\\sigma_{i}$ is the $i$-th singular value, and $\\lambda$ is the regularization parameter.\n",
    "This tells us what each mode of the [singular value decomposition](https://en.wikipedia.org/wiki/Singular_value_decomposition) contributes to the unknown parameter vector $\\hat{\\theta}_{\\lambda}$, which is __super cool__!!\n",
    "* Let's reconstruct the unknown parameters by summing the `r` modes of the data matrix $\\mathbf{X}$. First, let's set up the data matrix $\\mathbf{X}$, and compute the [singular value decomposition](https://en.wikipedia.org/wiki/Singular_value_decomposition) using the [svd function](https://docs.julialang.org/en/v1/stdlib/LinearAlgebra/#LinearAlgebra.svd) exported by the [Linear Algebra package](https://docs.julialang.org/en/v1/stdlib/LinearAlgebra/#man-linalg) in Julia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "182acd00-db9c-42a2-a4f3-da4c4db64d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = R[idx_of_ticker, :];\n",
    "max_length = length(Y);\n",
    "X = [ones(max_length) Rₘ];\n",
    "IM = diagm(ones(2)); # we have two parameters -"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9baf9db3-fde5-4b5d-adac-5a5ceeb9909c",
   "metadata": {},
   "source": [
    "Compute the [singular value decomposition](https://en.wikipedia.org/wiki/Singular_value_decomposition) using the [svd function](https://docs.julialang.org/en/v1/stdlib/LinearAlgebra/#LinearAlgebra.svd) exported by the [Linear Algebra package](https://docs.julialang.org/en/v1/stdlib/LinearAlgebra/#man-linalg) in Julia. By default, the Julia [svd function](https://docs.julialang.org/en/v1/stdlib/LinearAlgebra/#LinearAlgebra.svd) returns the singular values as a vector, so let's use the [diagm function](https://docs.julialang.org/en/v1/stdlib/LinearAlgebra/#LinearAlgebra.diagm) to compute a diagonal matrix from the singular value vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3bcfb5c7-1b85-4bd2-bfd1-35ab6d005ef9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2×2 Matrix{Float64}:\n",
       " 98.5355   0.0\n",
       "  0.0     39.4475"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(U,d,V) = svd(X);\n",
    "Σ = diagm(d) # the Julia SVD returns only the diagonal vector, using diagm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5a12aa-9425-46aa-b40a-ddcbc343c4b8",
   "metadata": {},
   "source": [
    "Next, let's compute the [rank](https://docs.julialang.org/en/v1/stdlib/LinearAlgebra/#LinearAlgebra.rank) of the data matrix $\\mathbf{X}\\in\\mathbb{R}^{n\\times{p}}$. We know that the rank $r\\leq\\min\\left(n,p\\right)$. But what is our intuition about rank?\n",
    "* __Alternative view__: The [rank](https://docs.julialang.org/en/v1/stdlib/LinearAlgebra/#LinearAlgebra.rank) is also the number of non-zero singular values; thus, we can think of the [rank](https://docs.julialang.org/en/v1/stdlib/LinearAlgebra/#LinearAlgebra.rank) as the number of unique pieces of information that are contained in the data matrix $\\mathbf{X}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1edb4d2b-977e-474e-a4d1-b8d217117048",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = rank(X) # the number of non-zero modes in the svd decomposition!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eedfce73-05aa-4454-8f4a-925d4b12167d",
   "metadata": {},
   "source": [
    "Now, we can compute the contribution to the unknown parameter vector $\\theta$ that comes from each mode of the [singular value decomposition](https://en.wikipedia.org/wiki/Singular_value_decomposition). The most important mode corresponds to the $\\beta$ parameter (risk), followed by the $\\alpha$, which is a measure of the firm-specific excess return:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "162d1c8c-2ca1-47f4-a2db-10a008539099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(i, θ̂) = (1, [0.009373526798496713, 0.8931133549095052])\n",
      "(i, θ̂) = (2, [-0.06439967698961394, 0.8938876296406101])\n"
     ]
    }
   ],
   "source": [
    "θ̂ = zeros(2); # we have two parameters -\n",
    "for i ∈ 1:r\n",
    "    \n",
    "\n",
    "    σᵢ = Σ[i,i];\n",
    "    uᵢ = U[:,i];\n",
    "    vᵢ = V[:,i];\n",
    "\n",
    "    # compute the coefficient -\n",
    "    cᵢ = (σᵢ*dot(transpose(uᵢ),Y))/(σᵢ^2 + λ)\n",
    "\n",
    "    # compute the parameter update -\n",
    "    θ̂ += cᵢ*vᵢ\n",
    "\n",
    "    @show (i, θ̂)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0263a166-8df9-45a3-9f91-5464abbb1eb9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.2",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
